# -*- coding: utf-8 -*-
import cv2
import numpy as np
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import re
import torch
from mtcnn import MTCNN
from openai import OpenAI
from PIL import Image, ImageFile, ImageDraw
from io import BytesIO
import logging
from torchvision.transforms import transforms
from skimage import feature

# å›¾åƒå¤„ç†é…ç½®
ImageFile.LOAD_TRUNCATED_IMAGES = True
MEDIAN_FILTER_SIZE = 5

# åˆå§‹åŒ–æ—¥å¿—
logging.basicConfig(
    format='%(asctime)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¥åº·å…ˆçŸ¥ - ä¸“ä¸šå¥åº·åˆ†æ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="collapsed"
)


def apply_custom_style():
    st.markdown(f"""
    <style>
        /* ä¿æŒåŸæœ‰æ ·å¼ä¸å˜ */
        .stTextInput label, 
        .stNumberInput label,
        .stTextArea label,
        .stSelectbox label,
        .stFileUploader label,
        .stCheckbox label,
        .stRadio label {{
            color: #000000 !important;
        }}
        body, .stApp, .stAlert, .stMarkdown {{
            color: #000000 !important;
        }}
        .stAlert svg,
        .stSuccess svg,
        .stWarning svg {{
            fill: #000000 !important;
        }}
        .stApp {{
            background-color: #808080;
            color: #000000 !important;
        }}
        
        .stTextInput input, 
        .stNumberInput input,
        .stTextArea textarea {{
            background-color: #ffffe0 !important;
            color: #000000 !important;
            border-radius: 8px;
        }}
        .stSelectbox select {{
            background-color: #ffffff !important;
            color: #000000 !important;
        }}
        .stFileUploader > div {{
            background-color: #ffffff !important;
            border: 2px dashed #4CAF50;
        }}
        /* æ–°å¢è¡¨å•æäº¤æŒ‰é’®ä¸“å±æ ·å¼ */
        div[data-testid="stFormSubmitButton"] button {{
            background-color: #000000 !important;
            color: #FFFFFF !important;
            border: 1px solid #FFFFFF !important;
        }}
        div[data-testid="stFormSubmitButton"] button:hover {{
            color: #FF0000 !important;
            background-color: #333333 !important;
            border-color: #FF0000 !important;
        }}
        .stButton button {{
            background-color: #000000 !important;  /* ä¿®æ”¹èƒŒæ™¯è‰²ä¸ºé»‘è‰² */
            color: #FFFFFF !important;            /* ä¿®æ”¹æ–‡å­—é¢œè‰²ä¸ºç™½è‰² */
            border-radius: 8px;
            padding: 0.5rem 2rem;
            border: 1px solid #ffffff;           /* æ·»åŠ ç™½è‰²è¾¹æ¡† */
            transition: all 0.3s ease;           /* æ·»åŠ è¿‡æ¸¡åŠ¨ç”» */
        }}
        /* æ‚¬åœçŠ¶æ€æ ·å¼ */
        .stButton button:hover {{
            color: #FF0000 !important;           /* æ‚¬åœæ—¶æ–‡å­—å˜çº¢ */
            background-color: #333333 !important; /* æ‚¬åœæ—¶èƒŒæ™¯è‰²ç¨äº® */
            border-color: #FF0000;               /* æ‚¬åœæ—¶è¾¹æ¡†å˜çº¢ */
        }}
        .stAlert {{ 
            background-color: #ffebee !important;
        }}
        .stDataFrame {{
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .medical-image {{
            border: 2px solid #2196F3;
            border-radius: 8px;
            padding: 5px;
        }}
        .face-marker {{
            border: 2px solid #FF5722 !important;
            border-radius: 50%;
            padding: 2px;
        }}
    </style>
    """, unsafe_allow_html=True)


apply_custom_style()


@st.cache_resource
def load_medical_models():
    face_detector = MTCNN(
        min_face_size=80,
        steps_threshold=[0.7, 0.8, 0.9],
        scale_factor=0.8
    )
    tongue_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)
    tongue_model.fc = torch.nn.Linear(512, 4)
    return face_detector, tongue_model


def get_deepseek_client():
    try:
        return OpenAI(
            api_key=st.secrets["DEEPSEEK_API_KEY"],
            base_url="https://api.deepseek.com/v1"
        )
    except KeyError:
        st.error("æœªæ‰¾åˆ°APIå¯†é’¥ï¼Œè¯·æ£€æŸ¥secrets.tomlé…ç½®")
        st.stop()
    except Exception as e:
        st.error(f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        st.stop()


class HealthScoreProcessor:
    @staticmethod
    def parse_scores(text):
        """æ”¹è¿›çš„è¯„åˆ†è§£ææ–¹æ³•"""
        score_patterns = {
            r'ç—‡çŠ¶ç—Šæ„ˆèƒ½åŠ›[^\d:]*è¯„åˆ†': 'ç—‡çŠ¶ç—Šæ„ˆèƒ½åŠ›è¯„åˆ†',
            r'é¥®é£Ÿ[^\d:]*è¯„åˆ†': 'é¥®é£Ÿè¯„åˆ†',
            r'ä»£è°¢[^\d:]*è¯„åˆ†': 'ä»£è°¢è¯„åˆ†',
            r'ç¡çœ [^\d:]*è¯„åˆ†': 'ç¡çœ è¯„åˆ†'
        }

        scores = {}
        for pattern, name in score_patterns.items():
            match = re.search(fr'{pattern}:\s*(\d+)/10', text)
            if match:
                scores[name] = int(match.group(1))
            else:
                scores[name] = 5  # é»˜è®¤å€¼
        return scores


class ChartGenerator:
    @staticmethod
    def create_radar_chart(scores):
        # ä¿æŒåŸæœ‰é›·è¾¾å›¾å®ç°ä¸å˜
        categories = list(scores.keys())
        values = list(scores.values())
        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(
            r=values + [values[0]],
            theta=categories + [categories[0]],
            fill='toself',
            line=dict(color='#4CAF50'),
            name='å¥åº·æŒ‡æ ‡'
        ))
        fig.update_layout(
            polar=dict(
                radialaxis=dict(range=[0, 10], gridcolor='#cccccc'),
                angularaxis=dict(gridcolor='#cccccc')
            ),
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            height=450,
            margin = dict(l=20, r=20, t=40, b=20)
        )
        return fig


def medical_preprocess(image_bytes):
    try:
        buffer = BytesIO(image_bytes)
        img = Image.open(buffer).convert('RGB')
        img_array = np.array(img)
        filtered = cv2.medianBlur(img_array, MEDIAN_FILTER_SIZE)
        return Image.fromarray(filtered)
    except Exception as e:
        logging.error(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {str(e)}")
        return None


class MedicalAnalyzer:
    def __init__(self):
        self.face_detector, self.tongue_model = load_medical_models()
        self.tongue_transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        self.eye_roi_scale = 1.5

    def _get_eye_regions(self, img_array, keypoints):
        """ä¿®æ­£çœ¼éƒ¨ROIè·å–é€»è¾‘"""
        eye_regions = []
        try:
            for eye_type in ['left_eye', 'right_eye']:
                if eye_type not in keypoints:
                    continue

                # è·å–åŒçœ¼åæ ‡è®¡ç®—è·ç¦»
                left_eye = keypoints['left_eye']
                right_eye = keypoints['right_eye']
                eye_distance = np.sqrt((left_eye[0] - right_eye[0]) ** 2 + (left_eye[1] - right_eye[1]) ** 2)

                # è®¡ç®—ROIå‚æ•°
                x_center, y_center = keypoints[eye_type]
                base_size = eye_distance * 0.3
                width = int(base_size * self.eye_roi_scale)
                height = int(width * 0.6)

                # è®¡ç®—åæ ‡è¾¹ç•Œ
                x1 = max(0, x_center - width // 2)
                y1 = max(0, y_center - height // 2)
                x2 = min(img_array.shape[1], x_center + width // 2)
                y2 = min(img_array.shape[0], y_center + height // 2)

                roi = img_array[y1:y2, x1:x2]
                if roi.size > 0:
                    eye_regions.append(roi)
        except Exception as e:
            logging.error(f"çœ¼éƒ¨åŒºåŸŸè·å–å¤±è´¥: {str(e)}")
        return eye_regions

    def _analyze_dark_circles(self, eye_roi):
        try:
            lab = cv2.cvtColor(eye_roi, cv2.COLOR_RGB2LAB)
            l_channel, a_channel, b_channel = cv2.split(lab)

            # é¢œè‰²åˆ†æ
            a_mean = np.mean(a_channel)
            l_std = np.std(l_channel)

            # çº¹ç†åˆ†æ
            radius = 2
            n_points = 8 * radius
            lbp = feature.local_binary_pattern(l_channel, n_points, radius, method="uniform")
            hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3))
            hist = hist.astype("float") / hist.sum()
            entropy = -np.sum(hist * np.log(hist + 1e-10))

            severity = 0.4 * a_mean + 0.3 * l_std + 0.3 * entropy
            return np.clip(severity / 100, 0, 1)
        except Exception as e:
            logging.error(f"é»‘çœ¼åœˆåˆ†æå¤±è´¥: {str(e)}")
            return 0.0

    def detect_dark_circles(self, image: Image.Image, keypoints: dict) -> float:
        try:
            img_array = np.array(image)
            eye_rois = self._get_eye_regions(img_array, keypoints)
            if not eye_rois:
                return 0.0

            scores = []
            for roi in eye_rois:
                if roi.size == 0:
                    continue
                score = self._analyze_dark_circles(roi)
                scores.append(score)

            return round(np.mean(scores), 2) if scores else 0.0
        except Exception as e:
            logging.error(f"é»‘çœ¼åœˆæ£€æµ‹å¤±è´¥: {str(e)}")
            return 0.0

    def analyze_face(self, image: Image.Image) -> dict:
        try:
            img_array = np.array(image)
            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)

            results = self.face_detector.detect_faces(img_array)
            if not results:
                return None

            main_face = max(results, key=lambda x: x['confidence'])
            keypoints = main_face['keypoints']

            # é»‘çœ¼åœˆæ£€æµ‹
            dark_circle_score = self.detect_dark_circles(image, keypoints)

            # çš®è‚¤åˆ†æ
            ycrcb = cv2.cvtColor(img_array, cv2.COLOR_RGB2YCrCb)
            _, cr, _ = cv2.split(ycrcb)
            skin_score = np.clip(cr.mean() / 140, 0, 1)

            return {
                'dark_circle': dark_circle_score,
                'skin_score': round(skin_score, 4),
                'keypoints': keypoints
            }
        except Exception as e:
            logging.error(f"é¢éƒ¨åˆ†æé”™è¯¯: {str(e)}")
            return None

    def analyze_tongue(self, image):
        try:
            img_tensor = self.tongue_transform(image).unsqueeze(0)
            if torch.cuda.is_available():
                img_tensor = img_tensor.cuda()
                self.tongue_model.cuda()

            with torch.no_grad():
                outputs = self.tongue_model(img_tensor)
                probs = torch.nn.functional.softmax(outputs, dim=1)

            return {
                'diagnosis': ['æ­£å¸¸', 'æ¹¿çƒ­', 'è¡€ç˜€', 'æ°”è™š'][torch.argmax(probs).item()],
                'confidence': probs[0].tolist(),
                'heatmap': self._generate_heatmap(image)
            }
        except Exception as e:
            logging.error(f"èˆŒè¯Šåˆ†æé”™è¯¯: {str(e)}")
            return None

    def _generate_heatmap(self, image):
        img_array = np.array(image)
        ycrcb = cv2.cvtColor(img_array, cv2.COLOR_RGB2YCrCb)
        _, cr, _ = cv2.split(ycrcb)
        heatmap = cv2.applyColorMap(cr, cv2.COLORMAP_JET)
        return Image.fromarray(cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB))


def main_app():
    client = get_deepseek_client()
    analyzer = MedicalAnalyzer()
    st.title("ğŸ¥ å¥åº·å…ˆçŸ¥æ™ºèƒ½åˆ†æç³»ç»Ÿdemo")
    st.markdown("---")

    with st.form("health_form"):
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ†” åŸºæœ¬ä¿¡æ¯")
            gender = st.selectbox("æ€§åˆ«*", ["ç”·", "å¥³"], index=0)
            age = st.number_input("å¹´é¾„*", min_value=1, max_value=120, value=30, step=1)
            height = st.number_input("èº«é«˜(cm)*", min_value=50, max_value=250, value=170, step=1)
            weight = st.number_input("ä½“é‡(kg)*", min_value=20, max_value=300, value=65, step=1)
            sleep = st.selectbox("ç¡çœ æƒ…å†µ*", ["è‰¯å¥½(ç¡çœ 7hä»¥ä¸Šï¼Œæ— å™©æ¢¦ï¼Œå…¥ç¡å¿«ï¼Œä¸­é€”æ— é†’ï¼‰", "ä¸€èˆ¬ï¼ˆç¡çœ 4-7hï¼Œå¤šæ¢¦ï¼Œå…¥ç¡è¾ƒæ…¢ï¼Œä¸­é€”å¶å°”é†’ï¼‰", "å·®ï¼ˆç¡çœ <4hï¼Œéš¾ä»¥å…¥ç¡ï¼‰"], index=1)

        with col2:
            st.subheader("ğŸ’Š å¥åº·æŒ‡æ ‡")
            symptoms = st.text_area("ç—‡çŠ¶æè¿°ï¼ˆå¦‚æœ‰æ…¢æ€§ç—…éœ€å¡«å…¥ï¼‰*", help="ä¾‹ï¼šæŒç»­ä¸‰å¤©å¤´ç—›ï¼Œä¼´æœ‰è½»å¾®å‘çƒ­...", height=120)
            diet = st.text_input("è¿‘æœŸé¥®é£Ÿ", help="ä¾‹ï¼šæœ€è¿‘ä¸‰å¤©ä»¥å¿«é¤ä¸ºä¸»...")
            temp = st.number_input("ä½“æ¸©(â„ƒ)", min_value=35.0, max_value=42.0, value=36.5, step=0.1)
            heart_rate = st.number_input("å¿ƒç‡(bpm)", min_value=30, max_value=200, value=75)

        st.subheader("ğŸ“¸ åŒ»å­¦å½±åƒä¸Šä¼ ")
        img_col1, img_col2 = st.columns(2)
        face_img = img_col1.file_uploader("é¢éƒ¨ç…§ç‰‡", type=["jpg", "png", "jpeg"])
        tongue_img = img_col2.file_uploader("èˆŒè‹”ç…§ç‰‡", type=["jpg", "png", "jpeg"])

        submitted = st.form_submit_button("ğŸš€ å¼€å§‹å…¨é¢åˆ†æ")

    if submitted:
        missing = []
        if not gender: missing.append("æ€§åˆ«")
        if not age: missing.append("å¹´é¾„")
        if not height: missing.append("èº«é«˜")
        if not weight: missing.append("ä½“é‡")
        if not symptoms.strip(): missing.append("ç—‡çŠ¶æè¿°")
        if not sleep: missing.append("ç¡çœ æƒ…å†µ")

        if missing:
            st.error(f"ç¼ºå°‘å¿…å¡«é¡¹: {', '.join(missing)}")
            st.stop()

        try:
            face_data, tongue_data = None, None
            processed_face, processed_tongue = None, None

            if face_img:
                processed_face = medical_preprocess(face_img.getvalue())
                if processed_face:
                    face_data = analyzer.analyze_face(processed_face)

            if tongue_img:
                processed_tongue = medical_preprocess(tongue_img.getvalue())
                if processed_tongue:
                    tongue_data = analyzer.analyze_tongue(processed_tongue)

            analysis_data = {
                "äººå£ç»Ÿè®¡": f"{gender}æ€§ | å¹´é¾„ {age}å² | èº«é«˜ {height}cm | ä½“é‡ {weight}kg",
                "ç—‡çŠ¶æè¿°": symptoms,
                "é¥®é£Ÿæƒ…å†µ": diet if diet.strip() else "æœªæä¾›è¯¦ç»†ä¿¡æ¯",
                "ç”Ÿç†æŒ‡æ ‡": f"ä½“æ¸© {temp}â„ƒ | å¿ƒç‡ {heart_rate}bpm" if temp or heart_rate else "æ— é¢å¤–ç”Ÿç†æŒ‡æ ‡",
                "ç¡çœ è´¨é‡": sleep,
                "é¢éƒ¨ç‰¹å¾": str(face_data) if face_data else "æœªæ£€æµ‹åˆ°äººè„¸",
                "èˆŒè‹”è¯Šæ–­": str(tongue_data) if tongue_data else "æœªæä¾›èˆŒè‹”å›¾åƒ"
            }

            # ä¿®æ”¹åçš„APIæç¤ºè¯
            with st.spinner("ğŸ” æ­£åœ¨åˆ†æåŸºç¡€æ•°æ®..."):
                chat_prompt = f"""ä½œä¸ºèµ„æ·±å…¨ç§‘åŒ»ç”Ÿï¼Œè¯·æŒ‰ä»¥ä¸‹è¦æ±‚åˆ†æå¥åº·æ•°æ®ï¼š
                {analysis_data}

                å¿…é¡»åŒ…å«ä»¥ä¸‹å››ä¸ªè¯„åˆ†é¡¹ï¼ˆåç§°ä¸¥æ ¼åŒ¹é…ï¼‰ï¼š
                1. ç—‡çŠ¶ç—Šæ„ˆèƒ½åŠ›è¯„åˆ†ï¼šæ ¹æ®ç—‡çŠ¶æè¿°çš„ç—Šæ„ˆèƒ½åŠ›è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
                2. é¥®é£Ÿè¯„åˆ†ï¼šæ ¹æ®é¥®é£Ÿå¥åº·ç¨‹åº¦è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
                3. ä»£è°¢è¯„åˆ†ï¼šæ ¹æ®BMIï¼ˆç”·/å¥³ï¼‰ã€é¢éƒ¨ç‰¹å¾å’Œç”Ÿç†æŒ‡æ ‡è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
                4. ç¡çœ è¯„åˆ†ï¼šæ ¹æ®ç¡çœ è´¨é‡ã€é¢éƒ¨ç‰¹å¾è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰

                è¾“å‡ºæ ¼å¼å¿…é¡»ä¸¥æ ¼éµå¾ªï¼š
                ### ç—‡çŠ¶ç—Šæ„ˆèƒ½åŠ›è¯„åˆ†: [æ•°å€¼]/10
                ### é¥®é£Ÿè¯„åˆ†: [æ•°å€¼]/10
                ### ä»£è°¢è¯„åˆ†: [æ•°å€¼]/10
                ### ç¡çœ è¯„åˆ†: [æ•°å€¼]/10
                ### æ½œåœ¨é£é™©: [å†…å®¹]
                ### å»ºè®®æ¡†æ¶: [å†…å®¹]"""

                chat_response = client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[{"role": "user", "content": chat_prompt}],
                    temperature=0.3,
                    max_tokens=1024
                ).choices[0].message.content

            # è§£æè¯„åˆ†
            processor = HealthScoreProcessor()
            final_scores = processor.parse_scores(chat_response)

            # éªŒè¯è¯„åˆ†
            required_scores = ['ç—‡çŠ¶ç—Šæ„ˆèƒ½åŠ›è¯„åˆ†', 'é¥®é£Ÿè¯„åˆ†', 'ä»£è°¢è¯„åˆ†', 'ç¡çœ è¯„åˆ†']
            if not all(key in final_scores for key in required_scores):
                st.warning("éƒ¨åˆ†è¯„åˆ†è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                final_scores = {key: final_scores.get(key, 5) for key in required_scores}

            with st.spinner("ğŸ§  è¿›è¡Œæ·±åº¦æ¨ç†åˆ†æ..."):
                reasoner_prompt = f"""åŸºäºä»¥ä¸‹åˆ†æç»“æœï¼š
                {chat_response}

                è¯·å®Œæˆï¼š
                1. ç”Ÿæˆç»¼åˆå¥åº·è¯„åˆ†ï¼ˆ0-100åˆ†åˆ¶ï¼‰
                2. åˆ›å»ºè¯¦ç»†çš„åˆ†é¡¹å¥åº·è¯„åˆ†è¡¨ï¼ˆç—‡çŠ¶ã€é¥®é£Ÿã€ä»£è°¢ã€ç¡çœ ï¼‰
                3. é¢„æµ‹æˆ–åˆ¤æ–­å¯èƒ½çš„ç—‡çŠ¶
                4. ç»™å‡ºåˆ†æ­¥éª¤çš„ä¸“ä¸šå»ºè®®
                5. åˆ—å‡ºéœ€è¦è­¦æƒ•çš„å±é™©ä¿¡å·
                6. é¢„ä¼°ç—‡çŠ¶æ¢å¤æ—¶é—´å‘¨æœŸå¹¶ç»™å‡ºä¾æ®

                è¦æ±‚ï¼š
                â€¢ åŒºåˆ†[æ€ç»´é“¾]å’Œ[æ­£å¼è¯Šæ–­]
                â€¢ è¯„åˆ†æ ‡å‡†ä¸å…¶ä»–å¥åº·æŒ‡æ ‡ä¿æŒä¸€è‡´
                â€¢ ä½¿ç”¨ä¸­æ–‡ä¸”æ˜“äºç†è§£"""

                reasoner_response = client.chat.completions.create(
                    model="deepseek-reasoner",
                    messages=[{"role": "user", "content": reasoner_prompt}],
                    temperature=0.2,
                    max_tokens=2048
                ).choices[0].message.content

            st.success("âœ… åˆ†æå®Œæˆï¼")
            st.markdown("---")

            if face_data and processed_face:
                with st.expander("ğŸ§‘ é¢éƒ¨å¥åº·æŠ¥å‘Š", expanded=True):
                    cols = st.columns([1, 2])
                    with cols[0]:
                        circle_score = face_data.get('dark_circle', 0)
                        status = "æ­£å¸¸" if circle_score < 0.3 else "è½»åº¦" if circle_score < 0.6 else "é‡åº¦"
                        st.metric("ğŸŸ¤ é»‘çœ¼åœˆæŒ‡æ•°",
                                  f"{circle_score * 10:.1f}/10 ({status})",
                                  help="0-3:æ­£å¸¸, 4-6:è½»åº¦, 7-10:é‡åº¦")
                        st.metric("çš®è‚¤å¥åº·åº¦",
                                  f"{face_data['skin_score'] * 10:.1f}/10",
                                  help="åŸºäºè‰²åº¦åˆ†æï¼Œæ•°å€¼è¶Šé«˜è¶Šå¥½")
                    with cols[1]:
                        draw_img = processed_face.copy()
                        draw = ImageDraw.Draw(draw_img)
                        for name, (x, y) in face_data['keypoints'].items():
                            draw.ellipse([x - 10, y - 10, x + 10, y + 10], outline="#FF5722", width=3)
                        st.image(draw_img,
                                 caption="é¢éƒ¨ç‰¹å¾ç‚¹åˆ†æ",
                                 use_column_width=True)

            if tongue_data and processed_tongue:
                with st.expander("ğŸ‘… èˆŒè±¡å¥åº·æŠ¥å‘Š", expanded=True):
                    cols = st.columns([1, 2])
                    with cols[0]:
                        st.metric("è¯Šæ–­ç»“æœ", tongue_data['diagnosis'])
                        st.metric("ç»¼åˆç½®ä¿¡åº¦", f"{max(tongue_data['confidence']) * 100:.1f}%")
                    with cols[1]:
                        st.image(tongue_data['heatmap'],
                                 caption="èˆŒä½“çƒ­åŠ›å›¾åˆ†æ",
                                 use_column_width=True)

            with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´è¯Šæ–­æŠ¥å‘Š", expanded=True):
                st.subheader("åˆæ­¥åˆ†æç»“æœ")
                st.markdown(chat_response)
                st.subheader("ç»¼åˆè¯Šæ–­æŠ¥å‘Š")
                st.markdown(reasoner_response)

            processor = HealthScoreProcessor()
            scores = processor.parse_scores(chat_response)
            final_scores = {
                "ç—‡çŠ¶ç—Šæ„ˆèƒ½åŠ›è¯„åˆ†": scores.get("ç—‡çŠ¶ç—Šæ„ˆèƒ½åŠ›è¯„åˆ†", 5),
                "é¥®é£Ÿè¯„åˆ†": scores.get("é¥®é£Ÿè¯„åˆ†", 5),
                "ä»£è°¢è¯„åˆ†": scores.get("ä»£è°¢è¯„åˆ†", 5),
                "ç¡çœ è¯„åˆ†": scores.get("ç¡çœ è¯„åˆ†", 5)
            }

            # å¥åº·æŒ‡æ ‡åˆ†æéƒ¨åˆ†
            st.subheader("ğŸ“Š å¥åº·æŒ‡æ ‡å¯è§†åŒ–")
            col_left, col_right = st.columns([1, 2])

            with col_left:
                df = pd.DataFrame.from_dict(final_scores, orient='index', columns=['è¯„åˆ†'])
                st.dataframe(
                    df.style.format(precision=0)
                    .highlight_between(left=0, right=5, color='#000000')
                    .highlight_between(left=6, right=8, color='#000000')
                    .highlight_between(left=9, right=10, color='#000000'),
                    use_container_width=True
                )

            with col_right:
                st.plotly_chart(
                    ChartGenerator.create_radar_chart(final_scores),
                    use_container_width=True
                )

        except Exception as e:
            st.error(f"ç³»ç»Ÿå‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}")
            logging.exception("ç³»ç»Ÿå´©æºƒ")
            st.stop()


if __name__ == "__main__":
    try:
        main_app()
    except ImportError as e:
        st.error(f"ç¼ºå°‘ä¾èµ–åº“: {str(e)}\nè¯·æ‰§è¡Œ: pip install mtcnn torchvision opencv-python-headless")
